{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "# reading input log file\n",
    "\n",
    "test_name = \"vist\"\n",
    "\n",
    "stat_path=f\"example_stat/{test_name}\"\n",
    "image_path=f\"{stat_path}/images\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My utility functions\n",
    "import utils.stat_loader as sload\n",
    "import utils.stat_print as sp\n",
    "import utils.vfd_stat2graph as vfd2g\n",
    "import utils.vfd_graph2sankey as vfd2sk\n",
    "import utils.full_stat2graph as f2g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve Functions\n",
    "## TODO\n",
    "- Add dataset nodes\n",
    "- Add file address ordering nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE_END is not in TASK_ORDER_LIST, set to max order: 1\n",
      "TASK_ORDER_LIST = {'arldm_saveh5': 0, 'arldm_train': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['arldm_saveh5', 'arldm_train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STAGE_START = 0\n",
    "STAGE_END = 2\n",
    "\n",
    "\n",
    "TASK_ORDER_LIST = sload.load_task_order_list(stat_path)\n",
    "STAGE_END = sload.correct_end_stage(TASK_ORDER_LIST, STAGE_END)\n",
    "\n",
    "TASK_ORDER_LIST = sload.current_task_order_list(TASK_ORDER_LIST, STAGE_START, STAGE_END)\n",
    "\n",
    "TASK_LISTS = list(TASK_ORDER_LIST.keys())\n",
    "\n",
    "print(f\"TASK_ORDER_LIST = {TASK_ORDER_LIST}\")\n",
    "TASK_LISTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vfd_files: ['example_stat/vist/271485-vfd_data_stat.json', 'example_stat/vist/271491-vfd_data_stat.json']\n",
      "loading example_stat/vist/271485-vfd_data_stat.json\n",
      "loading example_stat/vist/271491-vfd_data_stat.json\n",
      "vol_files: ['example_stat/vist/271485-vol_data_stat.json', 'example_stat/vist/271491-vol_data_stat.json']\n",
      "loading example_stat/vist/271485-vol_data_stat.json\n",
      "loading example_stat/vist/271491-vol_data_stat.json\n",
      "loading json done\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vfd_files = sload.find_files_with_pattern(stat_path, \"vfd\")\n",
    "# vfd_files = vfd_files[0:1]\n",
    "print(f\"vfd_files: {vfd_files}\")\n",
    "\n",
    "vfd_dict = sload.load_stat_json(vfd_files)\n",
    "# print(vfd_dict)\n",
    "\n",
    "\n",
    "vol_files = sload.find_files_with_pattern(stat_path, \"vol\")\n",
    "# vol_files = vol_files[0:1]\n",
    "print(f\"vol_files: {vol_files}\")\n",
    "\n",
    "vol_dict = sload.load_stat_json(vol_files)\n",
    "\n",
    "print(\"loading json done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total VFD overhead: 44.0 ms\n",
      "Total POSIX IO time: 177.0 ms\n"
     ]
    }
   ],
   "source": [
    "# Show VFD Tracker overhead\n",
    "sp.show_all_overhead(\"VFD\", vfd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat_file: example_stat/vist/271485-vfd_data_stat.json\n",
      "stat_file: example_stat/vist/271491-vfd_data_stat.json\n"
     ]
    }
   ],
   "source": [
    "def add_task_dset_file_nodes(G, stat_dict, task_list):\n",
    "    file_order_list = {} # keeptrack of dataset order in each file\n",
    "    task_order_list = {}\n",
    "    dset_order_list = {}\n",
    "    file_page_map = {} # keep track of dataset page map in each file\n",
    "    edge_stats = {} # All edge stats\n",
    "    layer = 0\n",
    "    for stat_file, stat_list in stat_dict.items():\n",
    "        print(f\"stat_file: {stat_file}\")\n",
    "        for li in stat_dict[stat_file]:\n",
    "            k = list(li.keys())[0]\n",
    "            if 'file' in k: # look for file entries\n",
    "                stat = li[k]\n",
    "                parts = k.split(\"-\")\n",
    "                node_order = int(parts[1])\n",
    "                if node_order not in file_order_list:\n",
    "                    file_order_list[node_order] = 0\n",
    "                \n",
    "                task_name = stat['task_name']\n",
    "                # Extract taskname without PID: e.g. arldm_saveh5-1119693 tp arldm_saveh5\n",
    "                task_name_base = task_name.split('-')[0]\n",
    "                \n",
    "                if task_name_base in task_list: # select task entries\n",
    "                    if task_name_base not in task_order_list: task_order_list[task_name_base] = 0\n",
    "                    else: task_order_list[task_name_base] += 1\n",
    "                    \n",
    "                    parts = k.split(\"-\")\n",
    "                    node_name = f\"{k} : {li[k]['file_name']}\"\n",
    "                    access_type = stat['access_type']\n",
    "                    # file_name = stat['file_name']\n",
    "                    file_name = os.path.basename(stat['file_name']) # FIXME: use basename for now\n",
    "                    node_order = int(parts[1])\n",
    "                    \n",
    "                    \n",
    "                    file_stat = {\"open_time\": stat['open_time'], \"close_time\": stat['close_time'], \n",
    "                                 \"file_intent\": stat['file_intent'], \n",
    "                                 \"file_read_cnt\": stat['file_read_cnt'], \n",
    "                                 \"file_write_cnt\": stat['file_write_cnt'], \n",
    "                                 \"access_type\": stat['access_type'], \"io_bytes\": stat['io_bytes'], \n",
    "                                 \"file_size\": stat['file_size']}\n",
    "                    \n",
    "                    # Get used dataset statastics of this file\n",
    "                    cur_dset_stats = f2g.get_all_dset_stat(stat)\n",
    "                    \n",
    "                    # Add file pages to file_page_map\n",
    "                    dataset_page_map = f2g.dset_page_map(cur_dset_stats)\n",
    "                    if file_name not in file_page_map:\n",
    "                        file_page_map[file_name] = dataset_page_map\n",
    "                    else:\n",
    "                        for dset, pages in dataset_page_map.items():\n",
    "                            if dset in file_page_map[file_name]:\n",
    "                                file_page_map[file_name][dset].extend(pages)\n",
    "                            else:\n",
    "                                file_page_map[file_name][dset] = pages\n",
    "                    \n",
    "                    # TODO: currently treat 'read_write' as 'write_only', 'read_write' as 'write_only'\n",
    "                    if access_type == 'read_only': # Initial input files\n",
    "                        file_x = 0\n",
    "                        addr_x = 1\n",
    "                        dset_x = 2\n",
    "                        task_x = 3\n",
    "                        # ORDER: file (-> file address) -> datasets -> task\n",
    "                        if not G.has_node(file_name):\n",
    "                            G.add_node(file_name, pos=(file_x+layer,node_order))\n",
    "                            file_node_attrs = {file_name: {'rpos':0, 'order': node_order, 'type':'file'}} # no stat here\n",
    "                            nx.set_node_attributes(G, file_node_attrs)\n",
    "                        else:\n",
    "                            # already has node, get x position as layer\n",
    "                            layer= G.nodes[file_name]['pos'][0]\n",
    "\n",
    "                        if not G.has_node(task_name):  # add task node\n",
    "                            G.add_node(task_name, pos=(task_x+layer,task_order_list[task_name_base]))\n",
    "                            # TODO: change to use VFD stats here\n",
    "                            task_node_attrs = {task_name: {'rpos':0, 'order': node_order, 'type':'task'}}\n",
    "                            nx.set_node_attributes(G, task_node_attrs)\n",
    "\n",
    "                        for dset, dset_stat in cur_dset_stats.items():\n",
    "                            dset_node = f\"{dset}-R\"\n",
    "                            if not G.has_node(dset_node):\n",
    "                                node_order = cur_dset_stats[dset]['order']\n",
    "                                G.add_node(dset_node, pos=(dset_x+layer,node_order))\n",
    "                                node_type = 'dataset'\n",
    "                                if dset == \"file\": node_type = 'file'\n",
    "                                dset_node_attrs = {dset_node: {'rpos':1, 'order': node_order, 'type':node_type, 'stat': dset_stat}}\n",
    "                                nx.set_node_attributes(G, dset_node_attrs)\n",
    "                            ftd_attr = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'file_stat':file_stat, 'edge_type':'file-dset'}\n",
    "                            if (file_name, dset_node) not in edge_stats:\n",
    "                                edge_stats[(file_name, dset_node)] = ftd_attr\n",
    "                            else:\n",
    "                                edge_stats[(file_name, dset_node)].update(ftd_attr)\n",
    "                            dtt_attr = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'file_stat':file_stat, 'edge_type':'dset-task'}\n",
    "                            if (dset_node, task_name) not in edge_stats:\n",
    "                                edge_stats[(dset_node, task_name)] = dtt_attr\n",
    "                            else:\n",
    "                                edge_stats[(dset_node, task_name)].update(dtt_attr)\n",
    "                            \n",
    "                            # edge_stats[(file_name, dset_node)] = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'stat':file_stat, 'edge_type':'file_to_dset'}                          \n",
    "                            # edge_stats[(dset_node, task_name)] = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'stat':file_stat, 'edge_type':'dset_to_task'}\n",
    "                        \n",
    "                    elif access_type == 'write_only' or access_type == 'read_write': # Intermediate files\n",
    "                        # ORDER: task -> datasets (-> file address) -> file\n",
    "                        file_x = 3\n",
    "                        addr_x = 2\n",
    "                        dset_x = 1\n",
    "                        task_x = 0\n",
    "                        if not G.has_node(task_name):  # add task node\n",
    "                            G.add_node(task_name, pos=(task_x+layer,task_order_list[task_name_base]))\n",
    "                            # TODO: change to use VFD stats here\n",
    "                            task_node_attrs = {task_name: {'rpos':0, 'order': node_order, 'type':'task'}}\n",
    "                            nx.set_node_attributes(G, task_node_attrs)\n",
    "                        else:\n",
    "                            # already has node, get x position as layer\n",
    "                            layer= G.nodes[task_name]['pos'][0]\n",
    "                        \n",
    "                        if not G.has_node(file_name):\n",
    "                            G.add_node(file_name, pos=(file_x+layer,node_order))\n",
    "                            file_node_attrs = {file_name: {'rpos':0, 'order': node_order, 'type':'file'}} # no stat here\n",
    "                            nx.set_node_attributes(G, file_node_attrs)\n",
    "                        \n",
    "                        for dset, dset_stat in cur_dset_stats.items():\n",
    "                            dset_node = f\"{dset}-W\"\n",
    "                            if not G.has_node(dset_node):\n",
    "                                node_order = cur_dset_stats[dset]['order']\n",
    "                                G.add_node(dset_node, pos=(dset_x+layer,node_order))\n",
    "                                node_type='dataset'\n",
    "                                if dset == \"file\": node_type = 'file'\n",
    "                                dset_node_attrs = {dset_node: {'rpos':1, 'order': node_order, 'type':node_type, 'stat': dset_stat}}\n",
    "                                nx.set_node_attributes(G, dset_node_attrs)\n",
    "                            ttd_attr = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'file_stat':file_stat, 'edge_type':'task-dset'}\n",
    "                            if (task_name, dset_node) not in edge_stats:\n",
    "                                edge_stats[(task_name, dset_node)] = ttd_attr\n",
    "                            else:\n",
    "                                edge_stats[(task_name, dset_node)].update(ttd_attr)\n",
    "                            dtf_attr = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'file_stat':file_stat, 'edge_type':'dset-file'}\n",
    "                            if (dset_node, file_name) not in edge_stats:\n",
    "                                edge_stats[(dset_node, file_name)] = dtf_attr\n",
    "                            else:\n",
    "                                edge_stats[(dset_node, file_name)].update(dtf_attr)\n",
    "\n",
    "                            # edge_stats[(task_name, dset_node)] = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'stat':file_stat, 'edge_type':'task_to_dset'}\n",
    "                            # edge_stats[(dset_node, file_name)] = {'label':task_name, 'dset_stat':dset_stat, 'access_type':access_type, 'stat':file_stat, 'edge_type':'dset_to_file'}\n",
    "\n",
    "                    layer+=2\n",
    "    G.add_edges_from(edge_stats.keys())\n",
    "    nx.set_edge_attributes(G, edge_stats)\n",
    "    return G\n",
    "\n",
    "\n",
    "G_VFD = nx.DiGraph()\n",
    "G_VFD = add_task_dset_file_nodes(G_VFD, vfd_dict, TASK_LISTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat_file: example_stat/vist/271485-vfd_data_stat.json\n",
      "stat_file: example_stat/vist/271491-vfd_data_stat.json\n",
      "file_page_nodes_attr: {'[0-567)': {'pos': (0, 0), 'rpos': 0, 'range': (0, 567), 'size': 37158912}, '[567-1134)': {'pos': (0, 1), 'rpos': 0, 'range': (567, 1134), 'size': 37158912}, '[1134-1701)': {'pos': (0, 2), 'rpos': 0, 'range': (1134, 1701), 'size': 37158912}, '[1701-2268)': {'pos': (0, 3), 'rpos': 0, 'range': (1701, 2268), 'size': 37158912}}\n",
      "dset_page_edges: {('[0-567)', 'dii'): {'access_cnt': 2, 'access_type': 'read'}, ('[1701-2268)', 'dii'): {'access_cnt': 2, 'access_type': 'read'}, ('dii', '[0-567)'): {'access_cnt': 2, 'access_type': 'write'}, ('[0-567)', 'file'): {'access_cnt': 42, 'access_type': 'read'}, ('[1701-2268)', 'file'): {'access_cnt': 2, 'access_type': 'read'}, ('file', '[1701-2268)'): {'access_cnt': 1, 'access_type': 'write'}, ('[0-567)', 'image0'): {'access_cnt': 10, 'access_type': 'read'}, ('[1701-2268)', 'image0'): {'access_cnt': 2, 'access_type': 'read'}, ('image0', '[0-567)'): {'access_cnt': 16, 'access_type': 'write'}, ('image0', '[1701-2268)'): {'access_cnt': 2, 'access_type': 'write'}, ('[0-567)', 'image1'): {'access_cnt': 12, 'access_type': 'read'}, ('[567-1134)', 'image1'): {'access_cnt': 2, 'access_type': 'read'}, ('image1', '[0-567)'): {'access_cnt': 6, 'access_type': 'write'}, ('image1', '[1134-1701)'): {'access_cnt': 1, 'access_type': 'write'}, ('image1', '[1701-2268)'): {'access_cnt': 4, 'access_type': 'write'}, ('[0-567)', 'image2'): {'access_cnt': 4, 'access_type': 'read'}, ('[1701-2268)', 'image2'): {'access_cnt': 2, 'access_type': 'read'}, ('image2', '[0-567)'): {'access_cnt': 4, 'access_type': 'write'}, ('image2', '[567-1134)'): {'access_cnt': 1, 'access_type': 'write'}, ('image2', '[1701-2268)'): {'access_cnt': 4, 'access_type': 'write'}, ('[0-567)', 'image3'): {'access_cnt': 2, 'access_type': 'read'}, ('[567-1134)', 'image3'): {'access_cnt': 1, 'access_type': 'read'}, ('[1701-2268)', 'image3'): {'access_cnt': 2, 'access_type': 'read'}, ('image3', '[0-567)'): {'access_cnt': 2, 'access_type': 'write'}, ('image3', '[567-1134)'): {'access_cnt': 1, 'access_type': 'write'}, ('image3', '[1134-1701)'): {'access_cnt': 1, 'access_type': 'write'}, ('image3', '[1701-2268)'): {'access_cnt': 7, 'access_type': 'write'}, ('[0-567)', 'image4'): {'access_cnt': 6, 'access_type': 'read'}, ('[1701-2268)', 'image4'): {'access_cnt': 2, 'access_type': 'read'}, ('image4', '[0-567)'): {'access_cnt': 1, 'access_type': 'write'}, ('image4', '[567-1134)'): {'access_cnt': 1, 'access_type': 'write'}, ('image4', '[1134-1701)'): {'access_cnt': 1, 'access_type': 'write'}, ('image4', '[1701-2268)'): {'access_cnt': 2, 'access_type': 'write'}, ('[0-567)', 'sis'): {'access_cnt': 16, 'access_type': 'read'}, ('[567-1134)', 'sis'): {'access_cnt': 2, 'access_type': 'read'}, ('[1701-2268)', 'sis'): {'access_cnt': 2, 'access_type': 'read'}, ('sis', '[0-567)'): {'access_cnt': 14, 'access_type': 'write'}, ('sis', '[1701-2268)'): {'access_cnt': 4, 'access_type': 'write'}}\n",
      "edges_to_add: dict_keys([('[0-567)-R', 'file-R'), ('vistsis_out.h5', '[0-567)-R'), ('[1701-2268)-R', 'file-R'), ('vistsis_out.h5', '[1701-2268)-R'), ('[0-567)-R', 'image3-R'), ('[567-1134)-R', 'image3-R'), ('vistsis_out.h5', '[567-1134)-R'), ('[1701-2268)-R', 'image3-R'), ('[0-567)-R', 'sis-R'), ('[567-1134)-R', 'sis-R'), ('[1701-2268)-R', 'sis-R'), ('[0-567)-R', 'image1-R'), ('[567-1134)-R', 'image1-R'), ('[0-567)-R', 'image4-R'), ('[1701-2268)-R', 'image4-R'), ('dii-W', '[0-567)-W'), ('[0-567)-W', 'vistsis_out.h5'), ('file-W', '[1701-2268)-W'), ('[1701-2268)-W', 'vistsis_out.h5'), ('image0-W', '[0-567)-W'), ('image0-W', '[1701-2268)-W'), ('image1-W', '[0-567)-W'), ('image1-W', '[1134-1701)-W'), ('[1134-1701)-W', 'vistsis_out.h5'), ('image1-W', '[1701-2268)-W'), ('image2-W', '[0-567)-W'), ('image2-W', '[567-1134)-W'), ('[567-1134)-W', 'vistsis_out.h5'), ('image2-W', '[1701-2268)-W'), ('image3-W', '[0-567)-W'), ('image3-W', '[567-1134)-W'), ('image3-W', '[1134-1701)-W'), ('image3-W', '[1701-2268)-W'), ('image4-W', '[0-567)-W'), ('image4-W', '[567-1134)-W'), ('image4-W', '[1134-1701)-W'), ('image4-W', '[1701-2268)-W'), ('sis-W', '[0-567)-W'), ('sis-W', '[1701-2268)-W')])\n",
      "edges_to_remove: [('vistsis_out.h5', 'file-R'), ('vistsis_out.h5', 'image3-R'), ('vistsis_out.h5', 'sis-R'), ('vistsis_out.h5', 'image1-R'), ('vistsis_out.h5', 'image4-R'), ('dii-W', 'vistsis_out.h5'), ('file-W', 'vistsis_out.h5'), ('image0-W', 'vistsis_out.h5'), ('image1-W', 'vistsis_out.h5'), ('image2-W', 'vistsis_out.h5'), ('image3-W', 'vistsis_out.h5'), ('image4-W', 'vistsis_out.h5'), ('sis-W', 'vistsis_out.h5')]\n",
      "add new node: [0-567)-R -> {'pos': (6, 0), 'rpos': 1, 'order': 0, 'type': 'addr', 'size': 37158912, 'range': (0, 567)}\n",
      "add new node: [1701-2268)-R -> {'pos': (6, 3), 'rpos': 1, 'order': 3, 'type': 'addr', 'size': 37158912, 'range': (1701, 2268)}\n",
      "add new node: [567-1134)-R -> {'pos': (6, 1), 'rpos': 1, 'order': 1, 'type': 'addr', 'size': 37158912, 'range': (567, 1134)}\n",
      "add new node: [0-567)-W -> {'pos': (4, 0), 'rpos': 1, 'order': 0, 'type': 'addr', 'size': 37158912, 'range': (0, 567)}\n",
      "add new node: [1701-2268)-W -> {'pos': (4, 3), 'rpos': 1, 'order': 3, 'type': 'addr', 'size': 37158912, 'range': (1701, 2268)}\n",
      "add new node: [1134-1701)-W -> {'pos': (4, 2), 'rpos': 1, 'order': 2, 'type': 'addr', 'size': 37158912, 'range': (1134, 1701)}\n",
      "add new node: [567-1134)-W -> {'pos': (4, 1), 'rpos': 1, 'order': 1, 'type': 'addr', 'size': 37158912, 'range': (567, 1134)}\n"
     ]
    }
   ],
   "source": [
    "def add_file_page(G, file_page_nodes_attr, dset_page_edges):\n",
    "    add_edge_stat = {}\n",
    "    edges_to_remove = []\n",
    "    nodes_to_add = {}\n",
    "    \n",
    "    for edge in G.edges():\n",
    "        edge_stat = G.edges[edge]\n",
    "        \n",
    "        if edge_stat['edge_type'] == 'file-dset': # read\n",
    "            # print(f\"edge: {edge} -> {edge_stat['dset_stat']}\")\n",
    "            access_type = edge_stat['access_type']\n",
    "            edges_to_remove.append(edge)\n",
    "            file_name = edge[0]\n",
    "            dset_name = edge[1]\n",
    "            \n",
    "            for page_dset_edge in dset_page_edges:\n",
    "                new_edge_stat = dset_page_edges[page_dset_edge]\n",
    "                page = page_dset_edge[0]\n",
    "                page_name = f\"{page}-R\"                    \n",
    "                new_dset_name = f\"{page_dset_edge[1]}-R\"\n",
    "                if new_dset_name == dset_name:\n",
    "                    # print(f\"new_edge: {new_edge}\")\n",
    "                    if not G.has_node(page_name):\n",
    "                        node_x = G.nodes[file_name]['pos'][0] + 1 # after file nodes\n",
    "                        node_order = file_page_nodes_attr[page]['pos'][1]\n",
    "                        nodes_to_add[page_name] = {page_name: {'pos':(node_x,node_order) , 'rpos':1, 'order': node_order, 'type':'addr', 'size': file_page_nodes_attr[page]['size'], 'range': file_page_nodes_attr[page]['range']}}\n",
    "                        page_stat = {'size': file_page_nodes_attr[page]['size'], 'range': file_page_nodes_attr[page]['range'], 'access_cnt': dset_page_edges[page_dset_edge]['access_cnt']}\n",
    "                        # Add page to dset edge\n",
    "                        add_edge_stat[(page_name, new_dset_name)] = {'label':edge_stat['label'], \n",
    "                                     'access_type':access_type, \n",
    "                                     'page_stat':page_stat,\n",
    "                                     'edge_type':'page-dset',\n",
    "                                     'file_stat':edge_stat['file_stat'],\n",
    "                                     'dset_stat':edge_stat['dset_stat']} \n",
    "                        # Add file to page edge\n",
    "                        add_edge_stat[(file_name, page_name)] = {'label':edge_stat['label'], \n",
    "                                     'access_type':access_type, \n",
    "                                     'page_stat':page_stat,\n",
    "                                     'edge_type':'file-page',\n",
    "                                     'file_stat':edge_stat['file_stat'],\n",
    "                                     'dset_stat':edge_stat['dset_stat']} \n",
    "                        \n",
    "        if edge_stat['edge_type'] == 'dset-file': # write\n",
    "            access_type = edge_stat['access_type']\n",
    "            edges_to_remove.append(edge)\n",
    "            file_name = edge[1]\n",
    "            dset_name = edge[0]\n",
    "            \n",
    "            for page_dset_edge in dset_page_edges:\n",
    "                new_edge_stat = dset_page_edges[page_dset_edge]\n",
    "                page = page_dset_edge[1]\n",
    "                page_name = f\"{page}-W\"\n",
    "                new_dset_name = f\"{page_dset_edge[0]}-W\"\n",
    "                if new_dset_name == dset_name:\n",
    "                    # print(f\"new_edge: {new_edge}\")\n",
    "                    if not G.has_node(page_name):\n",
    "                        node_x = G.nodes[dset_name]['pos'][0] + 1 # after dset nodes\n",
    "                        node_order = file_page_nodes_attr[page]['pos'][1]\n",
    "                        nodes_to_add[page_name] = {page_name: {'pos':(node_x,node_order) , 'rpos':1, 'order': node_order, 'type':'addr', 'size': file_page_nodes_attr[page]['size'], 'range': file_page_nodes_attr[page]['range']}}\n",
    "                        page_stat = {'size': file_page_nodes_attr[page]['size'], 'range': file_page_nodes_attr[page]['range'], 'access_cnt': dset_page_edges[page_dset_edge]['access_cnt']}\n",
    "                        # Add page to dset edge\n",
    "                        add_edge_stat[(new_dset_name, page_name)] = {'label':edge_stat['label'], \n",
    "                                     'access_type':access_type, \n",
    "                                     'page_stat':page_stat,\n",
    "                                     'edge_type':'dset-page',\n",
    "                                     'file_stat':edge_stat['file_stat'],\n",
    "                                     'dset_stat':edge_stat['dset_stat']}\n",
    "                        # Add file to page edge\n",
    "                        add_edge_stat[(page_name, file_name)] = {'label':edge_stat['label'], \n",
    "                                     'access_type':access_type, \n",
    "                                     'page_stat':page_stat,\n",
    "                                     'edge_type':'page-file',\n",
    "                                     'file_stat':edge_stat['file_stat'],\n",
    "                                     'dset_stat':edge_stat['dset_stat']} \n",
    "    \n",
    "\n",
    "    \n",
    "    return add_edge_stat, edges_to_remove, nodes_to_add\n",
    "\n",
    "\n",
    "\n",
    "file_page_nodes_attr, dset_page_edges = f2g.get_file_dset_maps(vfd_dict, TASK_LISTS)\n",
    "add_edge_stat,edges_to_remove,nodes_to_add = add_file_page(G_VFD, file_page_nodes_attr, dset_page_edges)\n",
    "# for k,v in add_edge_stat.items():\n",
    "#     print(f\"add_edge_stat: {k} -> {v}\")\n",
    "print(f\"edges_to_add: {add_edge_stat.keys()}\")\n",
    "print(f\"edges_to_remove: {edges_to_remove}\")\n",
    "G_VFD = f2g.update_nodes_edges(G_VFD,add_edge_stat, edges_to_remove, nodes_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_file_map = {'arldm_saveh5-271485': {'order': 0, 'io_cnt': 118, 'input': [], 'output': ['/home/mtang11/experiments/ARLDM/output_data/vistsis_out.h5']}, 'arldm_train-271491': {'order': 1, 'io_cnt': 17, 'input': ['/mnt/common/mtang11/experiments/ARLDM/output_data/vistsis_out.h5'], 'output': []}, 'arldm_train-271566': {'order': 1, 'io_cnt': 11, 'input': ['/mnt/common/mtang11/experiments/ARLDM/output_data/vistsis_out.h5'], 'output': []}}\n",
      "arldm_saveh5-271485 : {'order': 0, 'io_cnt': 118, 'input': [], 'output': ['/home/mtang11/experiments/ARLDM/output_data/vistsis_out.h5']}\n",
      "arldm_train-271491 : {'order': 1, 'io_cnt': 17, 'input': ['/mnt/common/mtang11/experiments/ARLDM/output_data/vistsis_out.h5'], 'output': []}\n",
      "arldm_train-271566 : {'order': 1, 'io_cnt': 11, 'input': ['/mnt/common/mtang11/experiments/ARLDM/output_data/vistsis_out.h5'], 'output': []}\n"
     ]
    }
   ],
   "source": [
    "task_file_map = sload.load_task_file_map(stat_path, test_name, TASK_LISTS)\n",
    "\n",
    "for task, stat in task_file_map.items():\n",
    "    print(f\"{task} : {stat}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_types: {'dset-task', 'task-dset', 'file-page', 'page-dset', 'page-file', 'dset-page'}\n"
     ]
    }
   ],
   "source": [
    "# G_VFD = vfd2g.set_task_position_full(G_VFD, task_file_map, STAGE_START)\n",
    "# sp.display_all_nodes_attr(G_VFD)\n",
    "all_edge_types = nx.get_edge_attributes(G_VFD,'edge_type')\n",
    "edge_types = []\n",
    "for edge in all_edge_types:\n",
    "    edge_types.append(all_edge_types[edge])\n",
    "\n",
    "print(f\"edge_types: {set(edge_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.display_all_nodes_attr(G_VFD)\n",
    "# G_VFD = vfd2g.set_file_position(G_VFD, task_file_map)\n",
    "\n",
    "\n",
    "sp.draw_graph(G_VFD, test_name, stat_path, graph_type=\"vfd\", prefix=f'{(STAGE_END+1)}s', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.display_all_edges_attr(G_VFD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add networkx to Sankey diagram\n",
    "\n",
    "## Statistics for Sankey\n",
    "Below are needed edge attributes before generating the sankey diagram:\n",
    "- access_cnt : The total file/dataset access count \n",
    "- access_size : The total read and write access size\n",
    "- operation : The operation type : read, write, read_write\n",
    "- bandwidth : Get the per access size and time, then calculate the bandwidth. Average the bandwidth if multiple accesses. (TODO: currently only recording one access size and time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2g.prepare_sankey_stat_full(G_VFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfd2sk.time_to_file_x_pos(G_VFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfd_nodes, vfd_nodes_dict = vfd2sk.get_nodes_for_sankey(G_VFD, label_on=True)\n",
    "\n",
    "# print(vfd_nodes)\n",
    "\n",
    "vfd_links = vfd2sk.get_links_for_sankey(G_VFD, vfd_nodes_dict, val_sqrt=False)\n",
    "fig = go.Figure(go.Sankey(\n",
    "            node = vfd_nodes,\n",
    "            link = vfd_links, orientation='h'))\n",
    "\n",
    "width = 2000\n",
    "height = 800\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    margin=dict(\n",
    "        l=width/100,\n",
    "        r=width/50,\n",
    "        b=height/100,\n",
    "        t=height/5,\n",
    "        pad=2\n",
    "    ),\n",
    "    font=dict(size=18),\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "save_html_path = f\"{stat_path}/vfd-{(STAGE_END+1)}s-{test_name}-sankey-labeled-s4.html\"\n",
    "fig.write_html(save_html_path)\n",
    "print(f\"Sankey saved to {save_html_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_str = sp.show_vfd_stats(G_VFD)\n",
    "print(stat_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a manual legend using annotations.\n",
    "\n",
    "def add_legend_to_graph(fig,save_img=False):\n",
    "    LEGEND_ITEMS = {\n",
    "        \"Tasks\":{\"color\":\"red\", \"text\":\"Tasks\"},\n",
    "        \"Files\":{\"color\":\"blue\", \"text\":\"Files\"},\n",
    "        \"Edges\":{\"color\":\"lightblue\", \"text\":\"File bandwidth, darker the color, higher the bandwidth\"},\n",
    "    }\n",
    "\n",
    "    legend_items = [\n",
    "        go.layout.Annotation(\n",
    "            x=0.9,  # X-coordinate for legend item\n",
    "            y=0.85 - i * 0.03,  # Y-coordinate for legend item (adjust for position)\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text=f\"{item_type} - {LEGEND_ITEMS[item_type]['color']}\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=14, color=LEGEND_ITEMS[item_type]['color']),\n",
    "            # bordercolor='grey',  # Set the border color for the legend box\n",
    "            # borderwidth=1,  # Set the border width for the legend box\n",
    "            bgcolor='rgba(255, 255, 255, 0.7)',  # Add a transparent background color\n",
    "        )\n",
    "        for i, item_type in enumerate(LEGEND_ITEMS.keys())\n",
    "    ]\n",
    "    fig.update_layout(annotations=legend_items)\n",
    "    fig.show()\n",
    "    if save_img:\n",
    "        fig.write_html(f\"{stat_path}/vfd-{(STAGE_END+1)}s-{test_name}-sankey-annotated.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
