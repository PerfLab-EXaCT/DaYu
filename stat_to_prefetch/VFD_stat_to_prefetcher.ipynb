{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# reading input log file\n",
    "# import ruamel.yaml\n",
    "import yaml\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import traceback\n",
    "from csv import excel\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "\n",
    "stat_path=\"../example_stat/1p9f9s_run\"\n",
    "iamge_path=f\"{stat_path}/images\"\n",
    "\n",
    "test_name = \"1p9f9s_run\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def search_files_with_name(directory, pattern):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if re.search(pattern, file):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "                #print(os.path.join(root, file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../example_stat/1p9f9s_run/5904_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/170958_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/75190_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/168881_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/167838_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/98522_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/11179_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/157121_vfd-data-stat-dl.yaml', '../example_stat/1p9f9s_run/77100_vfd-data-stat-dl.yaml']\n",
      "loading ../example_stat/1p9f9s_run/5904_vfd-data-stat-dl.yaml\n",
      "loading ../example_stat/1p9f9s_run/170958_vfd-data-stat-dl.yaml\n",
      "loading ../example_stat/1p9f9s_run/75190_vfd-data-stat-dl.yaml\n",
      "loading ../example_stat/1p9f9s_run/168881_vfd-data-stat-dl.yaml\n",
      "loading ../example_stat/1p9f9s_run/98522_vfd-data-stat-dl.yaml\n",
      "loading ../example_stat/1p9f9s_run/11179_vfd-data-stat-dl.yaml\n",
      "loading ../example_stat/1p9f9s_run/157121_vfd-data-stat-dl.yaml\n",
      "loading ../example_stat/1p9f9s_run/77100_vfd-data-stat-dl.yaml\n",
      "loading yaml done\n"
     ]
    }
   ],
   "source": [
    "vfd_files = search_files_with_name(stat_path, \"vfd\")\n",
    "# vfd_files = vfd_files[0:1]\n",
    "print(vfd_files)\n",
    "\n",
    "\n",
    "def load_vfd_yaml(vfd_files):\n",
    "    ret_dict = {}\n",
    "    tmp_dict = {}\n",
    "    for f in vfd_files:\n",
    "        if \"167838\" in f: # TODO: now only 7 stages\n",
    "            continue\n",
    "        else:\n",
    "            with open(f, \"r\") as stream:\n",
    "                print(f\"loading {f}\")\n",
    "                try:\n",
    "                    tmp_dict = yaml.safe_load(stream)\n",
    "                    # print(tmp_dict)\n",
    "                except yaml.YAMLError as exc:\n",
    "                    print(exc)\n",
    "                ret_dict[f] = tmp_dict\n",
    "    return ret_dict\n",
    "\n",
    "vfd_dict = load_vfd_yaml(vfd_files)\n",
    "# print(vfd_dict)\n",
    "\n",
    "print(\"loading yaml done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# op_range_shift_dict = {\n",
    "#     \"75190\":0,\n",
    "#     \"5904\":7208,\n",
    "#     \"77100\":12689,\n",
    "#     \"168881\":15641,\n",
    "#     \"98522\":30542,\n",
    "#     \"170958\":31599,\n",
    "#     \"11179\":34399,\n",
    "#     \"157121\":37801,\n",
    "#     # \"167838\":91681,\n",
    "# }\n",
    "\n",
    "# task_pid_dict = {\n",
    "#     \"run_idfeature\": {\"task_pid\":75190},\n",
    "#     \"run_tracksingle\": {\"task_pid\":5904},\n",
    "#     \"run_gettracks\": {\"task_pid\":77100},\n",
    "#     \"run_trackstats\": {\"task_pid\":168881},\n",
    "#     \"run_identifymcs\": {\"task_pid\":98522},\n",
    "#     \"run_matchpf\": {\"task_pid\":170958},\n",
    "#     \"run_mcsstats\": {\"task_pid\":11179},\n",
    "#     \"run_robustmcs\": {\"task_pid\":157121},\n",
    "#     # \"run_mapfeature\": {\"task_pid\":167838},\n",
    "#     # \"run_speed\": {\"task_pid\":??},\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# prefetch_entry_list = []\n",
    "\n",
    "# # get the I/O range\n",
    "# for k,stat in vfd_dict.items():\n",
    "#     # print(f\"VFD Stat File: {k}\")\n",
    "#     task_max_io = 0\n",
    "#     prev_file_max_io = 0\n",
    "#     file_op_range_dict = {}\n",
    "#     for li in stat:\n",
    "#         file_key = list(li.keys())[0]\n",
    "#         if 'file' in file_key:\n",
    "#             # file_stat = list(li.values())[0]\n",
    "#             file_stat = li[file_key]\n",
    "#             file_name = file_stat['file_name']\n",
    "#             file_max_io = 0\n",
    "#             file_min_io = prev_file_max_io\n",
    "#             file_max_blob = 0\n",
    "#             prefetch_type = 0 # 0: no prefetch, 1: prefetch blobs\n",
    "#             try:\n",
    "#                 h5mDraw = file_stat['data']['H5FD_MEM_DRAW']\n",
    "                \n",
    "#                 if h5mDraw['read_cnt'] > 0:\n",
    "#                     # print(f\"blobs here: {[val[1] for val in h5mDraw['read_ranges'].values()]}\")\n",
    "#                     max_blob = max([val[1] for val in h5mDraw['read_ranges'].values()])\n",
    "#                     max_io = max(h5mDraw['read_ranges'].keys())\n",
    "#                     min_io = min(h5mDraw['read_ranges'].keys())\n",
    "#                     if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "#                     if max_io > task_max_io: task_max_io = max_io\n",
    "#                     if max_io > file_max_io: file_max_io = max_io\n",
    "#                     if min_io < file_min_io: file_min_io = min_io\n",
    "#                     prefetch_type = 1\n",
    "                    \n",
    "#                 elif h5mDraw['write_cnt'] > 0:\n",
    "#                     # print(f\"blobs here: {[val[1] for val in h5mDraw['write_ranges'].values()]}\")\n",
    "#                     max_blob = max([val[1] for val in h5mDraw['write_ranges'].values()])\n",
    "#                     max_io = max(h5mDraw['write_ranges'].keys())\n",
    "#                     min_io = min(h5mDraw['read_ranges'].keys())\n",
    "#                     if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "#                     if max_io > task_max_io: task_max_io = max_io\n",
    "#                     if max_io > file_max_io: file_max_io = max_io\n",
    "#                     if min_io < file_min_io: file_min_io = min_io\n",
    "#                     prefetch_type = 0\n",
    "#                 else:\n",
    "#                     pass\n",
    "                \n",
    "#                 for meta_type, meta_stats in file_stat['metadata'].items():\n",
    "#                     # print(f\"meta_type: {meta_type}\")\n",
    "#                     if file_stat['metadata'][meta_type]['read_cnt'] > 0:\n",
    "#                         max_blob = max([val[1] for val in file_stat['metadata'][meta_type]['read_ranges'].values()])\n",
    "#                         max_io = max(file_stat['metadata'][meta_type]['read_ranges'].keys())\n",
    "#                         min_io = min(file_stat['metadata'][meta_type]['read_ranges'].keys())\n",
    "#                         if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "#                         if max_io > task_max_io: task_max_io = max_io\n",
    "#                         if max_io > file_max_io: file_max_io = max_io\n",
    "#                         if min_io < file_min_io: file_min_io = min_io\n",
    "#                         prefetch_type = 1\n",
    "                        \n",
    "#                     elif file_stat['metadata'][meta_type]['write_cnt'] > 0:\n",
    "#                         max_blob = max([val[1] for val in file_stat['metadata'][meta_type]['write_ranges'].values()])\n",
    "#                         max_io = max(file_stat['metadata'][meta_type]['write_ranges'].keys())\n",
    "#                         min_io = min(file_stat['metadata'][meta_type]['write_ranges'].keys())\n",
    "#                         if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "#                         if max_io > task_max_io: task_max_io = max_io\n",
    "#                         if max_io > file_max_io: file_max_io = max_io\n",
    "#                         if min_io < file_min_io: file_min_io = min_io\n",
    "#                         prefetch_type = 0\n",
    "#                     else:\n",
    "#                         pass\n",
    "                \n",
    "#                 # if \"cloudid_20150506_040000\" in file_name:\n",
    "#                 #     print(f\"VFD Stat File: {k}\")\n",
    "#                 #     print(f\"file_name: {file_name}\")\n",
    "#                 #     print(f\"file_io_range: [{file_min_io},{file_max_io}]\")\n",
    "#                 if file_name in file_op_range_dict.keys():\n",
    "#                     file_op_range_dict[file_name]['io_ranges'] .append((file_min_io, file_max_io))\n",
    "#                     if file_max_blob != file_op_range_dict[file_name]['blob_reanges'][1]:\n",
    "#                         file_op_range_dict[file_name]['blob_reanges'] = (0, file_max_blob)\n",
    "#                         file_op_range_dict[file_name]['prefetch_type'] = prefetch_type\n",
    "                        \n",
    "#                 else:\n",
    "#                     file_op_range_dict[file_name] = {}\n",
    "#                     file_op_range_dict[file_name]['io_ranges'] = [(file_min_io, file_max_io)]\n",
    "#                     file_op_range_dict[file_name]['blob_reanges'] = (0, file_max_blob)\n",
    "#                     file_op_range_dict[file_name]['prefetch_type'] = prefetch_type\n",
    "            \n",
    "#                 prev_file_max_io = file_max_io\n",
    "#                 if prefetch_type == 0:\n",
    "#                     print(f\"file_op_range_dict: {file_op_range_dict[file_name]}\")\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "\n",
    "#     file_name = k.split('/')[-1]\n",
    "#     task_id = file_name.split('_')[0]\n",
    "#     # print(f\"{task_id} Max IO IDX: {task_max_io}\")\n",
    "#     range_shift = op_range_shift_dict[task_id]\n",
    "#     page_size_factor = 1 # comparing to 1M, 512KB is 2 for 1M\n",
    "    \n",
    "#     for file_name, ranges_val in file_op_range_dict.items():\n",
    "#         for range in ranges_val['io_ranges']:\n",
    "#             pre_entry = {}\n",
    "#             # pre_entry['op_count_range'] = f\"[{page_size_factor*(range_shift+0)}, {page_size_factor*(range_shift+task_max_io)}]\"\n",
    "#             # pre_entry['op_count_range'] = [page_size_factor*(range_shift+range[0]), page_size_factor*(range_shift+range[1])]\n",
    "#             pre_entry['op_count_range'] = [page_size_factor*(range_shift), page_size_factor*(range_shift)]\n",
    "\n",
    "\n",
    "#             pre_entry['prefetch'] = []\n",
    "#             bucket_entry = {}\n",
    "#             bucket_entry['bucket'] = file_name\n",
    "#             # bucket_entry['promote_blobs'] = f\"[{page_size_factor*(ranges_val['blob_reanges'][0])}, {page_size_factor*(ranges_val['blob_reanges'][1])}]\"\n",
    "#             bucket_entry['blob_ranges'] = [page_size_factor*(ranges_val['blob_reanges'][0]), page_size_factor*(ranges_val['blob_reanges'][1])]\n",
    "#             bucket_entry['prefetch_type'] = \"promote_blobs\" if ranges_val['prefetch_type'] == 1 else \"demote_blobs\"\n",
    "            \n",
    "#             pre_entry['prefetch'].append(bucket_entry)\n",
    "#             prefetch_entry_list.append(pre_entry)\n",
    "            \n",
    "\n",
    "# with open('./apriori_p-1p9f-512KB.yml', 'w') as outfile:\n",
    "#     outfile.writelines(\"0:\\n\")\n",
    "#     sorted_entries = sorted(prefetch_entry_list, key=lambda x: x['op_count_range'][0])\n",
    "\n",
    "#     for ent in sorted_entries:\n",
    "#         # print(f\"  - op_count_range: {ent['op_count_range']}\")\n",
    "#         # print(f\"    prefetch:\")\n",
    "        \n",
    "#         outfile.writelines(f\"  - op_count_range: {ent['op_count_range']}\\n\")\n",
    "#         outfile.writelines(f\"    prefetch:\\n\")\n",
    "#         for bucket in ent['prefetch']:\n",
    "#             # print(f\"      - bucket: \\\"{bucket['bucket']}\\\"\")\n",
    "#             # print(f\"        promote_blobs: {bucket['promote_blobs']}\")\n",
    "#             # TODO: bucketname correction\n",
    "#             prefix = bucket['bucket'].split('_')[0]\n",
    "#             if prefix == \"cloudid\" or prefix == \"track\":\n",
    "#                 prefix_path = \"/qfs/projects/oddite/tang584/flextrkr_runs/hm_wrf_tbradar/tracking\"\n",
    "#             if prefix == \"mcs\" or prefix == \"trackstats\":\n",
    "#                 prefix_path = \"/qfs/projects/oddite/tang584/flextrkr_runs/hm_wrf_tbradar/stats\"\n",
    "#             if prefix == \"wrfout\" or prefix == \"wrf\":\n",
    "#                 prefix_path = \"/qfs/projects/oddite/tang584/flextrkr_runs/hm_input_data/wrf_tbradar\"\n",
    "#             bucket_name = prefix_path + \"/\" + bucket['bucket']\n",
    "#             outfile.writelines(f\"      - bucket: \\\"{bucket_name}\\\"\\n\")\n",
    "#             outfile.writelines(f\"        {bucket['prefetch_type']}: {bucket['blob_ranges']}\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_range_shift_dict = {\n",
    "    \"75190\":0,\n",
    "    \"5904\":7208,\n",
    "    \"77100\":12689,\n",
    "    \"168881\":15641,\n",
    "    \"98522\":30542,\n",
    "    \"170958\":31599,\n",
    "    \"11179\":34399,\n",
    "    \"157121\":37801,\n",
    "    # \"167838\":91681,\n",
    "}\n",
    "\n",
    "task_pid_dict = {\n",
    "    \"run_idfeature\": {\"task_pid\":75190},\n",
    "    \"run_tracksingle\": {\"task_pid\":5904},\n",
    "    \"run_gettracks\": {\"task_pid\":77100},\n",
    "    \"run_trackstats\": {\"task_pid\":168881},\n",
    "    \"run_identifymcs\": {\"task_pid\":98522},\n",
    "    \"run_matchpf\": {\"task_pid\":170958},\n",
    "    \"run_mcsstats\": {\"task_pid\":11179},\n",
    "    \"run_robustmcs\": {\"task_pid\":157121},\n",
    "    # \"run_mapfeature\": {\"task_pid\":167838},\n",
    "    # \"run_speed\": {\"task_pid\":??},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "prefetch_entry_list = []\n",
    "\n",
    "# get the I/O range\n",
    "for k,stat in vfd_dict.items():\n",
    "    # print(f\"VFD Stat File: {k}\")\n",
    "    task_max_io = 0\n",
    "    prev_file_max_io = 0\n",
    "    file_op_range_dict = {}\n",
    "    for li in stat:\n",
    "        file_key = list(li.keys())[0]\n",
    "        if 'file' in file_key:\n",
    "            # file_stat = list(li.values())[0]\n",
    "            file_stat = li[file_key]\n",
    "            file_name = file_stat['file_name']\n",
    "            file_max_io = 0\n",
    "            file_min_io = prev_file_max_io\n",
    "            file_max_blob = 0\n",
    "            prefetch_type = 0 # 0: no prefetch, 1: prefetch blobs\n",
    "            try:\n",
    "                h5mDraw = file_stat['data']['H5FD_MEM_DRAW']\n",
    "                \n",
    "                if h5mDraw['read_cnt'] > 0:\n",
    "                    # print(f\"blobs here: {[val[1] for val in h5mDraw['read_ranges'].values()]}\")\n",
    "                    max_blob = max([val[1] for val in h5mDraw['read_ranges'].values()])\n",
    "                    max_io = max(h5mDraw['read_ranges'].keys())\n",
    "                    min_io = min(h5mDraw['read_ranges'].keys())\n",
    "                    if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "                    if max_io > task_max_io: task_max_io = max_io\n",
    "                    if max_io > file_max_io: file_max_io = max_io\n",
    "                    if min_io < file_min_io: file_min_io = min_io\n",
    "                    prefetch_type = 1\n",
    "                    \n",
    "                elif h5mDraw['write_cnt'] > 0:\n",
    "                    # print(f\"blobs here: {[val[1] for val in h5mDraw['write_ranges'].values()]}\")\n",
    "                    max_blob = max([val[1] for val in h5mDraw['write_ranges'].values()])\n",
    "                    max_io = max(h5mDraw['write_ranges'].keys())\n",
    "                    min_io = min(h5mDraw['read_ranges'].keys())\n",
    "                    if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "                    if max_io > task_max_io: task_max_io = max_io\n",
    "                    if max_io > file_max_io: file_max_io = max_io\n",
    "                    if min_io < file_min_io: file_min_io = min_io\n",
    "                    prefetch_type = 0\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                for meta_type, meta_stats in file_stat['metadata'].items():\n",
    "                    # print(f\"meta_type: {meta_type}\")\n",
    "                    if file_stat['metadata'][meta_type]['read_cnt'] > 0:\n",
    "                        max_blob = max([val[1] for val in file_stat['metadata'][meta_type]['read_ranges'].values()])\n",
    "                        max_io = max(file_stat['metadata'][meta_type]['read_ranges'].keys())\n",
    "                        min_io = min(file_stat['metadata'][meta_type]['read_ranges'].keys())\n",
    "                        if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "                        if max_io > task_max_io: task_max_io = max_io\n",
    "                        if max_io > file_max_io: file_max_io = max_io\n",
    "                        if min_io < file_min_io: file_min_io = min_io\n",
    "                        prefetch_type = 1\n",
    "                        \n",
    "                    elif file_stat['metadata'][meta_type]['write_cnt'] > 0:\n",
    "                        max_blob = max([val[1] for val in file_stat['metadata'][meta_type]['write_ranges'].values()])\n",
    "                        max_io = max(file_stat['metadata'][meta_type]['write_ranges'].keys())\n",
    "                        min_io = min(file_stat['metadata'][meta_type]['write_ranges'].keys())\n",
    "                        if max_blob > file_max_blob: file_max_blob = max_blob\n",
    "                        if max_io > task_max_io: task_max_io = max_io\n",
    "                        if max_io > file_max_io: file_max_io = max_io\n",
    "                        if min_io < file_min_io: file_min_io = min_io\n",
    "                        prefetch_type = 0\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "                # if \"cloudid_20150506_040000\" in file_name:\n",
    "                #     print(f\"VFD Stat File: {k}\")\n",
    "                #     print(f\"file_name: {file_name}\")\n",
    "                #     print(f\"file_io_range: [{file_min_io},{file_max_io}]\")\n",
    "                if file_name in file_op_range_dict.keys():\n",
    "                    file_op_range_dict[file_name]['io_ranges'] .append((file_min_io, file_max_io))\n",
    "                    if file_max_blob != file_op_range_dict[file_name]['blob_reanges'][1]:\n",
    "                        file_op_range_dict[file_name]['blob_reanges'] = (0, file_max_blob)\n",
    "                        file_op_range_dict[file_name]['prefetch_type'] = prefetch_type\n",
    "                        \n",
    "                else:\n",
    "                    file_op_range_dict[file_name] = {}\n",
    "                    file_op_range_dict[file_name]['io_ranges'] = [(file_min_io, file_max_io)]\n",
    "                    file_op_range_dict[file_name]['blob_reanges'] = (0, file_max_blob)\n",
    "                    file_op_range_dict[file_name]['prefetch_type'] = prefetch_type\n",
    "            \n",
    "                prev_file_max_io = file_max_io\n",
    "                if prefetch_type == 0:\n",
    "                    print(f\"file_op_range_dict: {file_op_range_dict[file_name]}\")\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    file_name = k.split('/')[-1]\n",
    "    task_id = file_name.split('_')[0]\n",
    "    # print(f\"{task_id} Max IO IDX: {task_max_io}\")\n",
    "    range_shift = op_range_shift_dict[task_id]\n",
    "    page_size_factor = 1 # comparing to 1M, 512KB is 2 for 1M\n",
    "    \n",
    "    for file_name, ranges_val in file_op_range_dict.items():\n",
    "        for range in ranges_val['io_ranges']:\n",
    "            pre_entry = {}\n",
    "            # pre_entry['op_count_range'] = f\"[{page_size_factor*(range_shift+0)}, {page_size_factor*(range_shift+task_max_io)}]\"\n",
    "            # pre_entry['op_count_range'] = [page_size_factor*(range_shift+range[0]), page_size_factor*(range_shift+range[1])]\n",
    "            pre_entry['op_count_range'] = [page_size_factor*(range_shift), page_size_factor*(range_shift)]\n",
    "\n",
    "\n",
    "            pre_entry['prefetch'] = []\n",
    "            bucket_entry = {}\n",
    "            bucket_entry['bucket'] = file_name\n",
    "            # bucket_entry['promote_blobs'] = f\"[{page_size_factor*(ranges_val['blob_reanges'][0])}, {page_size_factor*(ranges_val['blob_reanges'][1])}]\"\n",
    "            bucket_entry['blob_ranges'] = [page_size_factor*(page_size_factor*ranges_val['blob_reanges'][0]), page_size_factor*(page_size_factor*ranges_val['blob_reanges'][1])]\n",
    "            bucket_entry['prefetch_type'] = \"promote_blobs\" if ranges_val['prefetch_type'] == 1 else \"demote_blobs\"\n",
    "            \n",
    "            pre_entry['prefetch'].append(bucket_entry)\n",
    "            prefetch_entry_list.append(pre_entry)\n",
    "            \n",
    "\n",
    "with open('./apriori_p-1p9f-512KB.yml', 'w') as outfile:\n",
    "    outfile.writelines(\"0:\\n\")\n",
    "    sorted_entries = sorted(prefetch_entry_list, key=lambda x: x['op_count_range'][0])\n",
    "\n",
    "    for ent in sorted_entries:\n",
    "        # print(f\"  - op_count_range: {ent['op_count_range']}\")\n",
    "        # print(f\"    prefetch:\")\n",
    "        \n",
    "        outfile.writelines(f\"  - op_count_range: {ent['op_count_range']}\\n\")\n",
    "        outfile.writelines(f\"    prefetch:\\n\")\n",
    "        for bucket in ent['prefetch']:\n",
    "            # print(f\"      - bucket: \\\"{bucket['bucket']}\\\"\")\n",
    "            # print(f\"        promote_blobs: {bucket['promote_blobs']}\")\n",
    "            # TODO: bucketname correction\n",
    "            prefix = bucket['bucket'].split('_')[0]\n",
    "            if prefix == \"cloudid\" or prefix == \"track\":\n",
    "                prefix_path = \"/qfs/projects/oddite/tang584/flextrkr_runs/hm_wrf_tbradar/tracking\"\n",
    "            if prefix == \"mcs\" or prefix == \"trackstats\":\n",
    "                prefix_path = \"/qfs/projects/oddite/tang584/flextrkr_runs/hm_wrf_tbradar/stats\"\n",
    "            if prefix == \"wrfout\" or prefix == \"wrf\":\n",
    "                prefix_path = \"/qfs/projects/oddite/tang584/flextrkr_runs/hm_input_data/wrf_tbradar\"\n",
    "            bucket_name = prefix_path + \"/\" + bucket['bucket']\n",
    "            outfile.writelines(f\"      - bucket: \\\"{bucket_name}\\\"\\n\")\n",
    "            outfile.writelines(f\"        {bucket['prefetch_type']}: {bucket['blob_ranges']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
